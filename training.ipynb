{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5L4Mq0C2mxR",
        "colab_type": "text"
      },
      "source": [
        "upzip image and mask Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc65x_fc2iY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! unzip \"train.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wnWmfZI3AVU",
        "colab_type": "text"
      },
      "source": [
        "image and mask path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyk5qhFx23aX",
        "colab_type": "code",
        "outputId": "2ec355d0-95e5-463f-9e37-4cea68f03f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "path_to_train = 'train'\n",
        "#os.chdir(path_to_train)\n",
        "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
        "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
        "\n",
        "train_img_paths = glob(glob_train_imgs)\n",
        "train_mask_paths = glob(glob_train_masks)\n",
        "print(train_img_paths[:10])\n",
        "print(train_mask_paths[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['train/44286_sat.jpg', 'train/25543_sat.jpg', 'train/49323_sat.jpg', 'train/8358_sat.jpg', 'train/50116_sat.jpg', 'train/50762_sat.jpg', 'train/35111_sat.jpg', 'train/4879_sat.jpg', 'train/43967_sat.jpg', 'train/21077_sat.jpg']\n",
            "['train/7181_msk.png', 'train/5529_msk.png', 'train/19553_msk.png', 'train/41031_msk.png', 'train/50738_msk.png', 'train/46794_msk.png', 'train/37746_msk.png', 'train/37833_msk.png', 'train/9013_msk.png', 'train/38605_msk.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtCSge3Z3mgT",
        "colab_type": "text"
      },
      "source": [
        "image generator from path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evuAFwtZ3MUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "# This will be useful so we can construct the corresponding mask\n",
        "def get_img_id(img_path):\n",
        "    img_basename = os.path.basename(img_path)\n",
        "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
        "    return img_id\n",
        "\n",
        "# Write it like a normal function\n",
        "def image_gen(img_paths, img_size=(256, 256)):\n",
        "    # Iterate over all the image paths\n",
        "    for img_path in img_paths:\n",
        "        \n",
        "        # Construct the corresponding mask path\n",
        "        img_id = get_img_id(img_path)\n",
        "        mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
        "        \n",
        "        # Load the image and mask, and normalize it to 0-1 range\n",
        "        img = imread(img_path) / 255.\n",
        "        mask = rgb2gray(imread(mask_path))\n",
        "        \n",
        "        # Resize the images\n",
        "        #img = resize(img, img_size, preserve_range=True)\n",
        "        #mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
        "        # Turn the mask back into a 0-1 mask\n",
        "        mask = (mask >= 0.5).astype(float)\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        yield img, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geuu8Hf23ilx",
        "colab_type": "text"
      },
      "source": [
        "metrics for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP1aYdCY3gFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "smooth = 1e-9\n",
        "\n",
        "# This is the competition metric implemented using Keras\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "# We'll construct a Keras Loss that incorporates the DICE score\n",
        "def dice_loss(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return 1. - (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return  0.5*binary_crossentropy(y_true, y_pred) + 0.5*dice_loss(y_true, y_pred)\n",
        "  \n",
        "def more_loss(y_true, y_pred):\n",
        "    return 2*dice_loss(y_true, y_pred)\n",
        "  \n",
        "def own_loss(y_true, y_pred):\n",
        "    y_true_f = K.cast(K.flatten(y_true), 'float32')\n",
        "    #y_pred_f = K.flatten(y_pred)\n",
        "    a = tf.cast(tf.constant(1),'float32')\n",
        "    b = tf.reduce_sum(y_true)\n",
        "    return tf.cond(b < a, lambda: more_loss(y_true, y_pred), lambda: dice_loss(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKZXXF7c3292",
        "colab_type": "text"
      },
      "source": [
        "image batch generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9faBoXf3q0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "#import img_msk_aug_gen as gen\n",
        "# Keras takes its input in batches \n",
        "# (i.e. a batch size of 32 would correspond to 32 images and 32 masks from the generator)\n",
        "# The generator should run forever\n",
        "def image_batch_generator(img_paths, batchsize=32):\n",
        "  #img_paths = np.random.shuffle(img_paths)\n",
        "  while True:\n",
        "    #shuffle image paths\n",
        "    img_paths = random.sample(img_paths, len(img_paths))\n",
        "    ig = image_gen(img_paths)\n",
        "    batch_img, batch_mask = [], []\n",
        "\n",
        "    for img, mask in ig:\n",
        "        # Add the image and mask to the batch\n",
        "        batch_img.append(img)\n",
        "        batch_mask.append(mask)\n",
        "        # If we've reached our batchsize, yield the batch and reset\n",
        "        if len(batch_img) == batchsize:\n",
        "            yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
        "            batch_img, batch_mask = [], []\n",
        "\n",
        "    # If we have an nonempty batch left, yield it out and reset\n",
        "    if len(batch_img) != 0:\n",
        "        yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
        "        batch_img, batch_mask = [], []   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8wX0Mex1r7Z",
        "colab_type": "text"
      },
      "source": [
        "image augamentation batch generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUEc3GBa1q-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import *\n",
        "from skimage.exposure import adjust_gamma\n",
        "operations = ['original', 'rot90','rot180','rot270', 'flipud', 'fliplr', 'bright','dark' ]\n",
        "#angles = [90,180,270]\n",
        "#axises = ['ud','lr']\n",
        "#brights = ['bright','dark']\n",
        "#translations = [(-50,0),(0,-50),(50,0),(0,50)]\n",
        "def image_aug_batch_generator(img_paths, batchsize = 32):\n",
        "    while True:\n",
        "        img_paths = random.sample(img_paths, len(img_paths))\n",
        "        ig = image_gen(img_paths)\n",
        "        batch_image, batch_mask = [],[]\n",
        "        for image, mask in ig:\n",
        "            operation = np.random.choice(operations,1)\n",
        "            if operation is 'rot90':\n",
        "              image = rotate(image, 90)\n",
        "              mask = rotate(mask, 90)\n",
        "            elif operation is 'rot180':\n",
        "              image = rotate(image, 180)\n",
        "              mask = rotate(mask, 180)\n",
        "            elif operation is 'rot270':\n",
        "              image = rotate(image, 270)\n",
        "              mask = rotate(mask, 270)\n",
        "            elif operation is 'bright':\n",
        "              image = adjust_gamma(image, 0.5)\n",
        "              mask = mask\n",
        "            elif operation is 'dark':\n",
        "              image = adjust_gamma(image, 2)\n",
        "              mask = mask\n",
        "            elif operation is 'flipud':\n",
        "              image = np.flipud(iamge)\n",
        "              mask = np.flipud(mask)\n",
        "            elif operation is 'fliplr':\n",
        "              image = np.fliplr(image)\n",
        "              mask = np.fliplr(mask)\n",
        "            else:\n",
        "              image = image\n",
        "              mask = mask\n",
        "            \n",
        "            batch_image.append(image)\n",
        "            batch_mask.append(mask)\n",
        "            if len(batch_image) == batchsize:\n",
        "                yield np.stack(batch_image, axis = 0), np.stack(batch_mask, axis = 0)\n",
        "                batch_image, batch_mask = [],[]\n",
        "        \n",
        "        if len(batch_image)!=0:\n",
        "            yield np.stack(batch_image, axis = 0), np.stack(batch_mask, axis = 0)\n",
        "            batch_iamge, batch_mask = [],[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_HnKD6ELHve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from skimage.exposure import *\n",
        "#image = imread('68707_sat.jpg')\n",
        "#image_adj_0 = adjust_gamma(image,0.5)\n",
        "#image_adj_2 = adjust_gamma(image, 2)\n",
        "#plt.imshow(image)\n",
        "#plt.show()\n",
        "#plt.imshow(image_adj_0)\n",
        "#plt.show()\n",
        "#plt.imshow(image_adj_2)\n",
        "#plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9phX9km39Cm",
        "colab_type": "text"
      },
      "source": [
        "model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW66jbBbo6W3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFT-JYCX0po_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuCjnn7mM7GL",
        "colab_type": "text"
      },
      "source": [
        "Saving models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9ekHLPcMbvB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBy1PMh2gDGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_paths = []\n",
        "for train_img_path in train_img_paths:\n",
        "  img_id = get_img_id(train_img_path)\n",
        "  mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
        "  mask = rgb2gray(imread(mask_path))\n",
        "  mask = (mask >= 0.5).astype(float)\n",
        "  area = np.sum(mask)\n",
        "  if area > 200:\n",
        "    train_paths.append(train_img_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJtG7hr935mS",
        "colab_type": "code",
        "outputId": "f17a7b12-aad4-4249-c1f2-14661b1671da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#from unet_simple_crfrnn import *\n",
        "from dlinknet import *\n",
        "from keras.callbacks import *\n",
        "\n",
        "BATCHSIZE = 8\n",
        "print('train_paths length is %d' %(len(train_paths)))\n",
        "# Split the data into a train and validation set\n",
        "train_img_paths, val_img_paths = train_test_split(train_paths, test_size=0.15)\n",
        "\n",
        "# Create the train and validation generators\n",
        "traingen = image_aug_batch_generator(train_img_paths, batchsize=BATCHSIZE)\n",
        "valgen = image_batch_generator(val_img_paths, batchsize=BATCHSIZE)\n",
        "\n",
        "\n",
        "def calc_steps(data_len, batchsize):\n",
        "    return (data_len + batchsize - 1) // batchsize\n",
        "\n",
        "# Calculate the steps per epoch\n",
        "train_steps = calc_steps(len(train_img_paths), BATCHSIZE)\n",
        "val_steps = (calc_steps(len(val_img_paths), BATCHSIZE))\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=3, min_lr=1e-6)\n",
        "checkpointer = ModelCheckpoint('dlinknet.h5', verbose=1, save_best_only=True)\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', patience = 20)\n",
        "\n",
        "#from keras.models import load_model\n",
        "#model = load_model(\"unet_dilation_reg_4.h5\", custom_objects = {\"bce_dice_loss\":bce_dice_loss,\"dice_coef\":dice_coef})\n",
        "#print('successfully loading')\n",
        "model = dlinknet_34()\n",
        "model.load_weights('weights_dlinknet_20.h5')\n",
        "#model.summary()\n",
        "model.compile(Adam(lr=1e-4), loss = dice_loss, metrics=[dice_coef])\n",
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "    traingen, \n",
        "    steps_per_epoch=train_steps, \n",
        "    epochs=80, # Change this to a larger number to train for longer\n",
        "    validation_data=valgen, \n",
        "    validation_steps=val_steps, \n",
        "    verbose=1,\n",
        "    callbacks = [reduce_lr,checkpointer, earlystop],\n",
        "    max_queue_size=2,# Change this number based on memory restrictions\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_paths length is 8900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-99c13cf1067f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#model = load_model(\"unet_dilation_reg_4.h5\", custom_objects = {\"bce_dice_loss\":bce_dice_loss,\"dice_coef\":dice_coef})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#print('successfully loading')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlinknet_34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights_dlinknet_20.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dlinknet.py\u001b[0m in \u001b[0;36mdlinknet_34\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdlinknet_34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0mresnet34_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;31m#base_model = VGG19(weights='imagenet')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;31m#base_model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/resnet34.py\u001b[0m in \u001b[0;36mresnet_34\u001b[0;34m(input_tensor, input_shape)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mweights_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resnet34_imagenet_1000_no_top.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading resnet34 weights successfully'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m#model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 8388608, sblock->base_addr = 0, stored_eof = 85521592)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaxvuMBX-zPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('weights_dlinknet_100.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfJFTXSY-53R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into a train and validation set\n",
        "train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=0.15)\n",
        "\n",
        "#to store low training score img paths, \n",
        "train_scores = {}\n",
        "train_paths = []\n",
        "with open('train_paths.txt', 'w') as f:\n",
        "    for train_img_path in train_img_paths:\n",
        "        img_id = get_img_id(train_img_path)\n",
        "        ori_img = imread(train_img_path)\n",
        "        test_img = ori_img/255\n",
        "        test_img = np.expand_dims(test_img, axis = 0)\n",
        "        mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
        "        mask = rgb2gray(imread(mask_path))\n",
        "        mask = (mask >= 0.5).astype(float)\n",
        "        mask = np.expand_dims(mask, axis = 0)\n",
        "        mask = np.expand_dims(mask, axis = -1)\n",
        "        loss, dice_coef = model.evaluate(test_img, mask)\n",
        "        if dice_coef < 0.6:\n",
        "            train_paths.append(train_img_path)\n",
        "            f.writelines(train_img_path + '\\n')\n",
        "            train_scores[img_id] = dice_coef"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk6DWs-k4JuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('dlinknet_light_110.h5')\n",
        "model.save_weights('weights_dlinknet_170.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CicLMV0eKiSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKKt6_Bj-6Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to see the training score distribution\n",
        "with open('train_scores.txt','w') as f:\n",
        "    for k, v in train_scores.items():\n",
        "        if v < 0.5:\n",
        "            f.writelines('id is {}, score is {} '.format(k, v) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCiLyI5Ykz5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_paths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muYY6RjZQ8a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('val_paths.txt', 'w') as f:\n",
        "    for val_img_path in val_img_paths:\n",
        "        f.write('%s\\n' % val_img_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2-nZFHBrI7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = {}\n",
        "for val_img_path in val_img_paths:\n",
        "    img_id = get_img_id(val_img_path)\n",
        "    ori_img = imread(val_img_path)\n",
        "    test_img = ori_img/255\n",
        "    test_img = np.expand_dims(test_img, axis = 0)\n",
        "    mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
        "    mask = rgb2gray(imread(mask_path))\n",
        "    mask = (mask >= 0.5).astype(float)\n",
        "    mask = np.expand_dims(mask, axis = 0)\n",
        "    mask = np.expand_dims(mask, axis = -1)\n",
        "    loss, dice_coef = model.evaluate(test_img, mask)\n",
        "    scores[img_id] = [loss, dice_coef]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sLOuGQyrMxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = []\n",
        "low_scores = []\n",
        "with open('low_score_ids.txt', 'w') as f:\n",
        "    for k, v in scores.items():\n",
        "        if v[1] <= 0.5:\n",
        "            f.writelines('id is {}, score is {} '.format(k, v) + '\\n')\n",
        "            low_scores.append(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0P9ECEeKg1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(low_scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CFiUM0kM1TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "areas = []\n",
        "count = 0\n",
        "for train_img_path in train_img_paths:\n",
        "  img = imread(train_img_path)\n",
        "  img_id = get_img_id(train_img_path)\n",
        "  mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
        "  mask = rgb2gray(imread(mask_path))\n",
        "  area = np.sum(mask)\n",
        "  if area > 0 and area < 100:\n",
        "    areas.append(area)\n",
        "    #print(img_id)\n",
        "    count += 1\n",
        "\n",
        "plt.hist(areas, bins = 100)\n",
        "plt.show()\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGywwc6gnDPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}